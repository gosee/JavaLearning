1.7实现
jdk1.7中采用Segment + HashEntry的方式进行实现，结构如下：

/**
 *每一个segment都是一个HashEntry<K,V>[] table， table中的每一个元素本质上都是一个HashEntry的单向队列.
 */
final Segment<K,V>[] segments;

transient Set<K> keySet;
transient Set<Map.Entry<K,V>> entrySet;
transient Collection<V> values;

/**
 *本质上Segment类就是一个小的hashmap，里面table数组存储了各个节点的数据，继承了ReentrantLock, 可以作为互拆锁使用
 */
static final class HashEntry<K,V> {
    final int hash;
 final K key;
 volatile V value;
 volatile HashEntry<K,V> next;
 // 基本节点，存储Key， Value值
 HashEntry(int hash, K key, V value, HashEntry<K,V> next) {
        this.hash = hash;
 this.key = key;
 this.value = value;
 this.next = next;
 }

put实现
当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据，实现如下：
场景：线程A和线程B同时执行相同Segment对象的put方法
1、线程A执行tryLock()方法成功获取锁，则把HashEntry对象插入到相应的位置；
2、线程B获取锁失败，则执行scanAndLockForPut()方法，在scanAndLockForPut方法中，会通过重复执行tryLock()方法尝试获取锁，在多处理器环境下，重复次数为64，单处理器重复次数为1，当执行tryLock()方法的次数超过上限时，则执行lock()方法挂起线程B；
3、当线程A执行完插入操作时，会通过unlock()方法释放锁，接着唤醒线程B继续执行；
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    HashEntry<K,V> node = tryLock() ? null :
        scanAndLockForPut(key, hash, value);
 V oldValue;
 try {
        HashEntry<K,V>[] tab = table;
 int index = (tab.length - 1) & hash;
 HashEntry<K,V> first = entryAt(tab, index);
 for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                K k;
 if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
 if (!onlyIfAbsent) {
                        e.value = value;
 ++modCount;
 }
                    break;
 }
                e = e.next;
 }
            else {
                if (node != null)
                    node.setNext(first);
 else
 node = new HashEntry<K,V>(hash, key, value, first);
 int c = count + 1;
 if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    rehash(node);
 else
 setEntryAt(tab, index, node);
 ++modCount;
 count = c;
 oldValue = null;
 break;
 }
        }
    } finally {
        unlock();
 }
    return oldValue;
}
size实现
因为ConcurrentHashMap是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个Segment的元素个数时，已经计算过的Segment同时可能有数据的插入或则删除，在1.7的实现中，采用了如下方式：
public int size() {
    // Try a few times to get accurate count. On failure due to
 // continuous async changes in table, resort to locking.
 final Segment<K,V>[] segments = this.segments;
 int size;
 boolean overflow; // true if size overflows 32 bits
 long sum; // sum of modCounts
 long last = 0L; // previous sum
 int retries = -1; // first iteration isn't retry
 try {
        for (;;) {
            if (retries++ == RETRIES_BEFORE_LOCK) {
                for (int j = 0; j < segments.length; ++j)
                    ensureSegment(j).lock(); // force creation
 }
            sum = 0L;
 size = 0;
 overflow = false;
 for (int j = 0; j < segments.length; ++j) {
                Segment<K,V> seg = segmentAt(segments, j);
 if (seg != null) {
                    sum += seg.modCount;
 int c = seg.count;
 if (c < 0 || (size += c) < 0)
                        overflow = true;
 }
            }
            if (sum == last)
                break;
 last = sum;
 }
    } finally {
        if (retries > RETRIES_BEFORE_LOCK) {
            for (int j = 0; j < segments.length; ++j)
                segmentAt(segments, j).unlock();
 }
    }
    return overflow ? Integer.MAX_VALUE : size;
}
先采用不加锁的方式，连续计算元素的个数，最多计算3次：
1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；
2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；


1.8实现

数据结构

1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，结构如下：


改进一：取消segments字段，直接采用transient volatile HashEntry<K,V>[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。
改进二：将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。对于hash表来说，最核心的能力在于将key hash之后能均匀的分布在数组中。如果hash之后散列的很均匀，那么table数组中的每个队列长度主要为0或者1。但实际情况并非总是如此理想，虽然ConcurrentHashMap类默认的加载因子为0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
 int hash = spread(key.hashCode());
 int binCount = 0;
 for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
// 如果table为空，初始化；否则，根据hash值计算得到数组索引i，如果tab[i]为空，直接新建节点Node即可。注：tab[i]实质为链表或者红黑树的首节点。
if (tab == null || (n = tab.length) == 0)
            tab = initTable();
 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            if (casTabAt(tab, i, null,
 new Node<K,V>(hash, key, value, null)))
                break; // no lock when adding to empty bin
 }
 // 如果tab[i]不为空并且hash值为MOVED，说明该链表正在进行transfer操作，返回扩容完成后的table。
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
 else {
            V oldVal = null;
// 针对首个节点进行加锁操作，而不是segment，进一步减少线程冲突
 synchronized (f) {
                if (tabAt(tab, i) == f) {
//如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点
                    if (fh >= 0) {
                        binCount = 1;
 for (Node<K,V> e = f;; ++binCount) {
                            K ek;
// 如果在链表中找到值为key的节点e，直接设置e.val = value即可。
 if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
 if (!onlyIfAbsent)
                                    e.val = value;
 break;
 }
// 如果没有找到值为key的节点，直接新建Node并加入链表即可。
                            Node<K,V> pred = e;
 if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
 value, null);
 break;
 }
                        }
                    }
 // 如果首节点为TreeBin类型，说明为红黑树结构，执行putTreeVal操作。
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
 binCount = 2;
 if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
 value)) != null) {
                            oldVal = p.val;
 if (!onlyIfAbsent)
                                p.val = value;
 }
                    }
                }
            }
//如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，
//如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值
            if (binCount != 0) {
// 如果节点数>＝8，那么转换链表结构为红黑树结构。
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
 if (oldVal != null)
                    return oldVal;
 break;
 }
        }
    }
// 计数增加1，有可能触发transfer操作(扩容)。
    addCount(1L, binCount);
 return null;
}
size实现
1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，实现如下：
if ((as = counterCells) != null ||
    !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
    CounterCell a; long v; int m;
 boolean uncontended = true;
 if (as == null || (m = as.length - 1) < 0 ||
        (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
        !(uncontended =
          U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
        fullAddCount(x, uncontended);
 return;
 }
    if (check <= 1)
        return;
 s = sumCount();
}

private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
 if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit(); // force initialization
 h = ThreadLocalRandom.getProbe();
 wasUncontended = true;
 }
    boolean collide = false; // True if last slot nonempty
 for (;;) {
        CounterCell[] as; CounterCell a; int n; long v;
//初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，使用CounterCell记录元素个数的变化；
 if ((as = counterCells) != null && (n = as.length) > 0) {
            if ((a = as[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {            // Try to attach new Cell
 CounterCell r = new CounterCell(x); // Optimistic create
 if (cellsBusy == 0 &&
                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                        boolean created = false;
 try {               // Recheck under lock
 CounterCell[] rs; int m, j;
 if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
 created = true;
 }
                        } finally {
                            cellsBusy = 0;
 }
                        if (created)
                            break;
 continue; // Slot is now non-empty
 }
                }
                collide = false;
 }
            else if (!wasUncontended)       // CAS already known to fail
 wasUncontended = true; // Continue after rehash
 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))
                break;
 else if (counterCells != as || n >= NCPU)
                collide = false; // At max size or stale
 else if (!collide)
                collide = true;
//如果CounterCell数组counterCells为空，调用fullAddCount()方法进行初始化，并插入对应的记录数，通过CAS设置cellsBusy字段，只有设置成功的线程才能初始化CounterCell数组
 else if (cellsBusy == 0 &&
                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                try {
                    if (counterCells == as) {// Expand table unless stale
 CounterCell[] rs = new CounterCell[n << 1];
 for (int i = 0; i < n; ++i)
                            rs[i] = as[i];
 counterCells = rs;
 }
                } finally {
                    cellsBusy = 0;
 }
                collide = false;
 continue; // Retry with expanded table
 }
            h = ThreadLocalRandom.advanceProbe(h);
 }
        else if (cellsBusy == 0 && counterCells == as &&
                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
            boolean init = false;
 try {                           // Initialize table
 if (counterCells == as) {
                    CounterCell[] rs = new CounterCell[2];
 rs[h & 1] = new CounterCell(x);
 counterCells = rs;
 init = true;
 }
            } finally {
                cellsBusy = 0;
 }
            if (init)
                break;
 }
//如果通过CAS设置cellsBusy字段失败的话，则继续尝试通过CAS修改baseCount字段，如果修改baseCount字段成功的话，就退出循环，否则继续循环插入CounterCell对象；
        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))
            break; // Fall back on using base
 }
}
所以在1.8中的size实现比1.7简单多，因为元素个数保存baseCount中，部分元素的变化个数保存在CounterCell数组中，实现如下：
public int size() {
    long n = sumCount();
 return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}
final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
 long sum = baseCount;
 if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
 }
    }
    return sum;
}
